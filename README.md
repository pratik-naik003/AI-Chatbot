
AI Chatbot using LangGraph, ChatCerebras & Streamlit
This project is a streaming AI chatbot built using LangGraph, LangChain, Cerebras (Qwen model), and Streamlit.

It demonstrates:

Agentic AI workflow using LangGraph

Stateful chat with memory

Streaming responses in Streamlit UI

Secure API key handling using Streamlit Secrets

Features

ğŸ” LangGraph-based workflow

ğŸ§  Chat memory using checkpointer

âš¡ Fast inference via Cerebras (Qwen model)

ğŸ’¬ Streaming chat UI with Streamlit


ğŸ—ï¸ Project Structure
ai-chatbot/
â”‚
â”œâ”€â”€ frontend.py          # Streamlit UI
â”œâ”€â”€ backend.py           # LangGraph + ChatCerebras logic
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ .gitignore           # Ignore secrets & venv
â”œâ”€â”€ .env.example         # Example environment variables
â””â”€â”€ README.md            # Project documentation

ğŸ§© Tech Stack

Python 3.11

Streamlit â€“ frontend UI

LangChain â€“ LLM interface

LangGraph â€“ agent workflow & memory

ChatCerebras â€“ LLM (Qwen)

Cerebras Cloud SDK

ğŸ”‘ Environment Variables
Required
Variable	Description
CEREBRAS_API_KEY	Your Cerebras Cloud API key
ğŸ” API Key Setup (IMPORTANT)
ğŸ”¹ Local Development

Create a .env file:

CEREBRAS_API_KEY=your_api_key_here

ğŸ”¹ Streamlit Cloud Deployment

Go to Streamlit App â†’ Settings â†’ Secrets

Add:

CEREBRAS_API_KEY = "your_api_key_here"

ğŸ“¦ Installation (Local)
1ï¸âƒ£ Create virtual environment
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

â–¶ï¸ Run the App Locally
streamlit run frontend.py


App will start at:

http://localhost:8501

ğŸ§  How It Works
ğŸ”¹ Backend (backend.py)

Uses LangGraph StateGraph

Maintains message history

Calls ChatCerebras (Qwen model)

Stores memory using InMemorySaver

ğŸ”¹ Frontend (frontend.py)

Streamlit chat interface

Stores messages in st.session_state

Streams assistant responses in real time

ğŸ”„ LangGraph Workflow
START â†’ chat_node â†’ END


chat_node receives messages

Sends them to Cerebras LLM

Returns updated state with AI response

ğŸ“„ requirements.txt (Recommended)
streamlit>=1.52.0
langchain>=1.2.0,<2.0.0
langchain-community>=0.4.0
langgraph>=1.0.0
cerebras-cloud-sdk>=1.59.0
python-dotenv>=1.0.0

ğŸ‘¨â€ğŸ’» Author

Built by Pratik Naik
B.Tech AI/ML | LangGraph | Agentic AI
